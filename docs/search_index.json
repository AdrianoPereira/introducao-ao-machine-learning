[
["introdução.html", "Agrupamento 1 Introdução 1.1 Machine learning", " Agrupamento 1 Introdução “As máquinas podem pensar?” A pergunta acima faz parte de um exercício teórico proposto pelo cientista da computação Alan Turing em seu artigo publicado em 1950 (TURING 1950). Conhecido também como jogo da imitação, o teste de Turing constitui, em sua concepção inicial, na interação entre três agentes: um agente interrogador e dois agentes respondentes, onde um dos agentes repondentes é um ser humano e outro uma máquina (computador). A pergunta enviada pelo agente interrogador é recebida por ambos os agentes respondentes, onde cada um deles devem enviar de volta a resposta. Com base nas respostas, o agente interrogador deve determinar quem é o humano é que é a máquina, a partir do momento em que esse agente não consegue mais fazer essa diferenciação, é dito que a máquina passou no teste. A Figura 1.1 mostra o esquema básico desse teste. Figure 1.1: Esquema do teste de Turing clássico. Diversas derivações desse teste surgiram posteriormente, o mais famoso deles e familiar entre a maioria dos internautas é o CAPTCHA (Completely Automated Public Turing test to tell Computers and Humans Apart), mecanismo de seguraça proposto por Von Ahn et al. (2003) para validar requisições através da resolução de pequenos desafios, que podem ser identificação de imagens ou textos distorcidos e com ruídos, e que tem como propósito dificultar o acesso não convencional a formulários, por exemplo, tentar impedir o uso bots. O teste de Turing talvez tenha sido um ponto de partida para o que hoje conhecemos por aprendizado de máquina (ML - sigla do inglês, Machine Learning) . A possibilidade de representar pensamentos em computadores, similares aos dos seres vivos foi um grande marco na humanidade. Atualmente esse conceito está sendo aplicado nas mais diversas áreas, tendo em algumas tarefas, o desempenho superior ao dos seres humanos. O próprio CAPTCHA é um exemplo disso, em algumas de suas versões iniciais o conteúdo ficava tão distorcido, que acabava dificultando a sua identificação pelos humanos, em contrapartida, os algoritmos conseguiam resolver o desafio com certa facilidade. Neste capítulo, será apresentada uma visão geral sobre o Machine Learning, discorrendo sobre as principais classes de algoritmos e aplicações com ênfase na área espacial. Ao final deste capítulo o leitor deverá ser capaz de: Compreender o contexto histórico e a definição do ML; Diferenciar as principais abordagens de treinamento dos modelos de ML; Diferenciar as principais classes de algoritmos de ML; Compreender as etapas mínimas necessárias para a produção de um modelo de ML; 1.1 Machine learning O ML é composto por uma coleção de métodos criados a partir de modelos matemáticos baseados na teoria da estatística que permitem aos computadores automatizarem tarefas com base na descoberta sistemática de padrões nos conjuntos de dados disponíveis ou em experiências passadas (Bhavsar et al. 2017; Alpaydin 2020). Segundo a definição de Samuel (1959), um dos pioneiros do assunto, o aprendizado de máquina é “um campo de estudo que oferece aos computadores a capacidade de aprender sem serem explicitamente programados”. "],
["classificação.html", "2 Classificação", " 2 Classificação Lorem ipsum dolor sit amet "],
["regressão.html", "3 Regressão 3.1 Regressão Linear", " 3 Regressão Todas as pessoas pelo menos uma vez na vida já sentiu ou sentirá a necessidade de prever algum acontecimento futuro. Estamos a todo momento assimilando informações para realizar alguma tomada de decisão, seja de forma intrínseca ou não. No contexto de Machine Learning (ML) isso é feito pela técnicas de regressão. A regressão é uma ferramenta que busca modelar relações entre variáveis dependentes e independentes através de métodos estatísticos (Soto 2013). Uma variável independente, normalmente representada pela variável \\(x\\), caracteriza uma grandeza que está sendo manipulada durante um experimento e que não sofre influência de outras variáveis. Já a variável dependente, normalmente representada pela variável \\(y\\), caracteriza valores que estão diretamente associados à variável independente, ou seja, ao ser manipulada os valores variável independente, o valor das variáveis dependentes também sofrem alterações. Na Figura 3.1 é apresentada a relação entre a expectativa de vida baseada e um índice de felicidade calculado em diversos países obtidos a partir de um levantamento feito por Helliwell et al. (2020). A variável independente nesse exemplo é representada pelo índice de felicidade e a expectativa de vida age como variável independente, dessa forma pode ser observada uma tendência de expectativa de vida maior em países com alto índice de felicidade, com uma força de correlação de 0,77. Figure 3.1: Relação entre o índice de felicidade e expectativa de vida. Fonte: (Helliwell et al. 2020) As relações entre as variáveis dependentes e independetes são feitas através de algum coeficiente de correlação. Uma das métricas de correlação mais utilizadas é o coeficiente de Pearson, que mede a associação linear entre duas variáveis (Kirch 2008). Os valores do coeficiente de Pearson variam entre -1 e 1, de tal forma que quanto mais próximos desses extremos, melhor correlacionado estão as variáveis. A Figura 3.2 mostra alguns exemplos com gráficos de disperssão de variáveis com diferentes correlações. Figure 3.2: Diferentes correlações entre variáveis. Fonte: (Helliwell et al. 2020) Os métodos de regressão se utilizam dessas correlações entre as variáveis para estimar valores não existentes na amostra ou conjunto de dados. Entretanto, nem sempre essas correlações são tão explicítas assim, sendo necessário outras abordagens mais robustas para realizar as previsões.Em ML os modelos de regressão podem ser criados a partir de diversas abordagens, desde as mais simples com poucas configurações de parâmetros e de fácil interpretação do funcionamento, até as abordagens mais complexas. Os métodos de regressão abordados neste capítulo serão Regressão linear, Máquina de vetores de suporte e Árvores de decisão. 3.1 Regressão Linear A regressão linear é um dos métodos mais intuitivos e utilizados para essa finalidade. Esses métodos são dividos em dois grupos, a regressão linear simples (RLS) e regressão linear múltipla (RLM). A RLS tem como objetivo estabelecer uma relação entre duas variáveis através de uma função, que pode ser definida por: \\[\\begin{equation} y_{i} = \\alpha+\\beta x_{i} \\tag{3.1} \\end{equation}\\] Onde \\(y_{i}\\) é a variável dependente, também denominada de variável alvo, \\(\\alpha\\) e \\(beta x_{i}\\) são coeficientes calculados pela regressão, que representam o intercepto no eixo \\(y\\) e inclinação da reta, respectivamente. A RLM é semelhante semelhante à RLS, porém possui multiplas variáveis preditoras, e pode ser definida por: \\[\\begin{equation} y_{i} = \\alpha+\\beta x_{i1}+\\beta x_{i2}+...+\\beta x_{in} \\tag{3.2} \\end{equation}\\] Onde \\(y_{i}\\) é a variável dependente, \\(\\alpha\\) continua sendo o coeficiente de intercepto e \\(\\beta x_{ip}\\) o é coeficiente angular da \\(p\\)-ésima variável. Ambos os métodos podem ainda serem somados a um termo \\(\\epsilon\\) de erro. 3.1.1 Cálculo dos coeficientes Existem diversas abordagens para se calcular os coeficientes de intercepto de inclinação da reta, as técnicas baseadas em mínimos quadrados oridinários e gradiente descendente são as mais comuns. 3.1.1.1 Métodos dos quadrados ordinários O Método dos quadrados ordinários (MQO) ou método dos mínimos quadrados (MMQ), busca encontrar o melhor valor para os coeficientes citados anteriormente, de tal forma que a diferença absoluta entre o valor real e o predito pela função seja a menor possível entre todos os pontos. A Figura 3.3 mostra um exmplo de regressão linar utilizando o MQO para um conjunto de pontos com força de correlação de 0,9. Figure 3.3: Exemplo do método dos quadrados ordinários. Considerando a Imagem 3.3, uma amostra de 10 pontos como exemplo, que será chamada de \\(A\\), ou seja, \\(A = \\{(x_{i}, y_{i}):i=1, ..., 10\\}\\). O MQO tem como objetivo estibular os coeficientes da função, de tal forma que a soma quadrática dos erros absolutos \\(E^{2}\\) seja a menor possível: \\[\\begin{equation} E^{2} = \\sum_{i=1}^{n=10}(y_{i}-(\\alpha+\\beta x_{i}))^{2} \\tag{3.3} \\end{equation}\\] Expandindo a equação fica: \\[\\begin{equation} E = ((y_{1}-(\\alpha+\\beta x_{1}))^{2}+(y_{2}-(\\alpha+\\beta x_{2}))^{2}+ ... + (y_{10}-(\\alpha+\\beta x_{10}))^{2})^{2} \\tag{3.4} \\end{equation}\\] Após isso, é teremos uma função com duas variáveis, e para encontrar seus valores e igualar a zero, a fim de se obter os pontos críticos, é necessário calcular as derivadas parciais em relação a \\(\\alpha\\) (Equação (3.5) e \\(\\beta\\) (Equação (3.6). \\[\\begin{equation} \\frac{\\partial E^{2}}{\\partial \\alpha} = (y_{1}-(\\alpha+\\beta x_{1}))^{2}+(y_{2}-(\\alpha+\\beta x_{2}))^{2}+ ... + (y_{10}-(\\alpha+\\beta x_{10}))^{2} = 0 \\tag{3.5} \\end{equation}\\] \\[\\begin{equation} \\frac{\\partial E^{2}}{\\partial \\beta} = (y_{1}-(\\alpha+\\beta x_{1}))^{2}+(y_{2}-(\\alpha+\\beta x_{2}))^{2}+ ... + (y_{10}-(\\alpha+\\beta x_{10}))^{2} = 0 \\tag{3.6} \\end{equation}\\] Após calcular as derivadas parcias, teremos duas equações, das quais podemos encontrar os valores das duas variáveis utilizando um sistema de equações lineares. Após encontrar as variáveis e realizar as devidas substituições, teremos a equação da reta, ou seja, a regressão linear. 3.1.1.2 Gradiente descendente O método do gradiente descendente (GD) é uma das técnicas mais utilizadas para otimização de modelos de ML. O GD é um método interativo que busca encontrar os coeficiente \\(\\alpha\\) e \\(\\beta\\) através da minimuzação de uma função de custo, normalmente o erro quadrático médio (MSE - sigla do inglês, mean squared error). O MSE pode ser definido pela Equação (3.7), onde \\(e_{i}\\) é a diferença entre o valor real de \\(y_{i}\\) e o valor previsto pela equação. \\[\\begin{equation} MSE = \\frac{1}{n} \\sum^{n}_{i=1}e_{i}^{2} \\tag{3.7} \\end{equation}\\] O GD deve ajustar os coeficientes até que o MSE seja o menor possível e cada intereação. A atualização dos coeficiente é feita com base em uma taxa de aprendizado, normalmente definida em 0,0001. Uma taxa de aprendizado muito grande o GD pode cair em um mínimo local, já um valor muito baixo, o modelo pode demorar muito mais tempo para chegar em um mínimo local, necessitando de muito mais tempo e processamento, conforme ilustrado na Figura 3.4. Figure 3.4: Problemas na taxa de aprendizado do gradiente descendente. "],
["agrupamento.html", "4 Agrupamento", " 4 Agrupamento Lorem ipsum dolor sit amet "],
["considerações-finais.html", "5 Considerações finais", " 5 Considerações finais Lorem ipsum dolor sit amet "],
["referências-bibliográficas.html", "6 Referências Bibliográficas", " 6 Referências Bibliográficas Alpaydin, Ethem. 2020. Introduction to Machine Learning. MIT press. Bhavsar, Parth, Ilya Safro, Nidhal Bouaynaya, Robi Polikar, and Dimah Dera. 2017. “Machine Learning in Transportation Data Analytics.” In Data Analytics for Intelligent Transportation Systems, 283–307. Elsevier. Helliwell, John F, Haifang Huang, Shun Wang, and Max Norton. 2020. “Social Environments for World Happiness.” World Happiness Report 2020. Kirch, Wilhelm, ed. 2008. “Pearson’s Correlation Coefficient.” In Encyclopedia of Public Health, 1090–1. Dordrecht: Springer Netherlands. https://doi.org/10.1007/978-1-4020-5614-7_2569. Samuel, Arthur L. 1959. “Some Studies in Machine Learning Using the Game of Checkers.” IBM Journal of Research and Development 3 (3): 210–29. Soto, Timothy. 2013. “Regression Analysis.” In Encyclopedia of Autism Spectrum Disorders, edited by Fred R. Volkmar, 2538–8. New York, NY: Springer New York. TURING, A. M. 1950. “COMPUTING MACHINERY AND INTELLIGENCE.” Mind LIX (236): 433–60. https://doi.org/10.1093/mind/LIX.236.433. Von Ahn, Luis, Manuel Blum, Nicholas J Hopper, and John Langford. 2003. “CAPTCHA: Using Hard Ai Problems for Security.” In International Conference on the Theory and Applications of Cryptographic Techniques, 294–311. Springer. "]
]
