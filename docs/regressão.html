<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>3 Regressão | Agrupamento</title>
  <meta name="description" content="3 Regressão | Agrupamento" />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="3 Regressão | Agrupamento" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="3 Regressão | Agrupamento" />
  
  
  




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="classificação.html"/>
<link rel="next" href="agrupamento.html"/>
<script src="libs/header-attrs-2.3/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>



</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="introdução.html"><a href="introdução.html"><i class="fa fa-check"></i><b>1</b> Introdução</a>
<ul>
<li class="chapter" data-level="1.1" data-path="introdução.html"><a href="introdução.html#machine-learning"><i class="fa fa-check"></i><b>1.1</b> Machine learning</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="classificação.html"><a href="classificação.html"><i class="fa fa-check"></i><b>2</b> Classificação</a></li>
<li class="chapter" data-level="3" data-path="regressão.html"><a href="regressão.html"><i class="fa fa-check"></i><b>3</b> Regressão</a>
<ul>
<li class="chapter" data-level="3.1" data-path="regressão.html"><a href="regressão.html#regressão-linear"><i class="fa fa-check"></i><b>3.1</b> Regressão Linear</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="regressão.html"><a href="regressão.html#cálculo-dos-coeficientes"><i class="fa fa-check"></i><b>3.1.1</b> Cálculo dos coeficientes</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="agrupamento.html"><a href="agrupamento.html"><i class="fa fa-check"></i><b>4</b> Agrupamento</a></li>
<li class="chapter" data-level="5" data-path="considerações-finais.html"><a href="considerações-finais.html"><i class="fa fa-check"></i><b>5</b> Considerações finais</a></li>
<li class="chapter" data-level="6" data-path="referências-bibliográficas.html"><a href="referências-bibliográficas.html"><i class="fa fa-check"></i><b>6</b> Referências Bibliográficas</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Agrupamento</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="regressão" class="section level1" number="3">
<h1><span class="header-section-number">3</span> Regressão</h1>
<p>Todas as pessoas pelo menos uma vez na vida já sentiu ou sentirá a necessidade
de prever algum acontecimento futuro. Estamos a todo momento assimilando
informações para realizar alguma tomada de decisão, seja de forma intrínseca ou
não. No contexto de Machine Learning (ML) isso é feito pela técnicas de
regressão. A regressão é uma ferramenta que busca modelar relações entre
variáveis dependentes e independentes através de métodos estatísticos
<span class="citation">(Soto 2013)</span>.</p>
<p>Uma variável independente, normalmente representada pela variável <span class="math inline">\(x\)</span>,
caracteriza uma grandeza que está sendo manipulada durante um experimento e que
não sofre influência de outras variáveis. Já a variável dependente, normalmente
representada pela variável <span class="math inline">\(y\)</span>, caracteriza valores que estão diretamente
associados à variável independente, ou seja, ao ser manipulada os valores
variável independente, o valor das variáveis dependentes também sofrem
alterações. Na Figura <a href="regressão.html#fig:happinessWorld">3.1</a> é apresentada a relação entre a
expectativa de vida baseada e um índice de felicidade calculado em diversos
países obtidos a partir de um levantamento feito por <span class="citation">Helliwell et al. (2020)</span>. A
variável independente nesse exemplo é representada pelo índice de felicidade e a
expectativa de vida age como variável independente, dessa forma pode ser
observada uma tendência de expectativa de vida maior em países com alto índice
de felicidade, com uma força de correlação de 0,77.</p>
<div class="figure" style="text-align: center"><span id="fig:happinessWorld"></span>
<img src="assets/happiness_world.png" alt="Relação entre o índice de felicidade e expectativa de vida. Fonte: [@helliwell2020social]"  />
<p class="caption">
Figure 3.1: Relação entre o índice de felicidade e expectativa de vida. Fonte: <span class="citation">(Helliwell et al. 2020)</span>
</p>
</div>
<p>As relações entre as variáveis dependentes e independetes são feitas através de
algum coeficiente de correlação. Uma das métricas de correlação mais utilizadas
é o coeficiente de Pearson, que mede a associação linear entre duas variáveis
<span class="citation">(Kirch 2008)</span>. O coeficiente de Pearson de amostras populacionais
pertecentes a duas variáveis pode ser definido pela
Equação <a href="regressão.html#eq:corr-pearson">(3.1)</a>.</p>
<p><span class="math display" id="eq:corr-pearson">\[\begin{equation} 
    r_{xy} = \frac{{}\sum_{i=1}^{n} (x_i - \overline{x})(y_i - \overline{y})}
    {\sqrt{\sum_{i=1}^{n} (x_i - \overline{x})^2(y_i - \overline{y})^2}}
\tag{3.1}
\end{equation}\]</span></p>
<p>Os valores do coeficiente de Pearson variam entre -1 e 1, de tal forma que
quanto mais próximos desses extremos, melhor correlacionado estão as variáveis.
A Figura <a href="regressão.html#fig:scatterCorrelations">3.2</a> mostra alguns exemplos com gráficos de
disperssão de variáveis com diferentes correlações.</p>
<div class="figure" style="text-align: center"><span id="fig:scatterCorrelations"></span>
<img src="assets/correlations.png" alt="Diferentes correlações entre variáveis. Fonte: [@helliwell2020social]"  />
<p class="caption">
Figure 3.2: Diferentes correlações entre variáveis. Fonte: <span class="citation">(Helliwell et al. 2020)</span>
</p>
</div>
<p>Os métodos de regressão se utilizam dessas correlações entre as variáveis para
estimar valores não existentes na amostra ou conjunto de dados. Entretanto, nem
sempre essas correlações são tão explicítas assim, sendo necessário outras
abordagens mais robustas para realizar as previsões.Em ML os modelos de
regressão podem ser criados a partir de diversas abordagens, desde as mais
simples com poucas configurações de parâmetros e de fácil interpretação do
funcionamento, até as abordagens mais complexas. Os métodos de regressão
abordados neste capítulo serão <code>Regressão linear</code>,
<code>Máquina de vetores de suporte</code> e <code>Árvores de decisão</code>.</p>
<div id="regressão-linear" class="section level2" number="3.1">
<h2><span class="header-section-number">3.1</span> Regressão Linear</h2>
<p>A regressão linear é um dos métodos mais intuitivos e utilizados para essa
finalidade. Esses métodos são dividos em dois grupos, a regressão linear simples
(RLS) e regressão linear múltipla (RLM). A RLS tem como objetivo estabelecer uma
relação entre duas variáveis através de uma função, que pode ser definida por:</p>
<p><span class="math display" id="eq:rls-function">\[\begin{equation} 
    y_{i} = \alpha+\beta x_{i}
\tag{3.2}
\end{equation}\]</span></p>
<p>Onde <span class="math inline">\(y_{i}\)</span> é a variável dependente, também denominada de variável alvo,
<span class="math inline">\(\alpha\)</span> e <span class="math inline">\(beta x_{i}\)</span> são coeficientes calculados pela regressão, que
representam o intercepto no eixo <span class="math inline">\(y\)</span> e inclinação da reta, respectivamente.</p>
<p>A RLM é semelhante semelhante à RLS, porém possui multiplas variáveis
preditoras, e pode ser definida por:</p>
<p><span class="math display" id="eq:rlm-function">\[\begin{equation} 
    y_{i} = \alpha+\beta x_{i1}+\beta x_{i2}+...+\beta x_{in}
\tag{3.3}
\end{equation}\]</span></p>
<p>Onde <span class="math inline">\(y_{i}\)</span> é a variável dependente, <span class="math inline">\(\alpha\)</span> continua sendo o coeficiente de
intercepto e <span class="math inline">\(\beta x_{ip}\)</span> o é coeficiente angular da <span class="math inline">\(p\)</span>-ésima variável. Ambos
os métodos podem ainda serem somados a um termo <span class="math inline">\(\epsilon\)</span> de erro.</p>
<div id="cálculo-dos-coeficientes" class="section level3" number="3.1.1">
<h3><span class="header-section-number">3.1.1</span> Cálculo dos coeficientes</h3>
<p>Existem diversas abordagens para se calcular os coeficientes de intercepto de
inclinação da reta, as técnicas baseadas em mínimos quadrados oridinários e
gradiente descendente são as mais comuns.</p>
<div id="métodos-dos-quadrados-ordinários" class="section level4" number="3.1.1.1">
<h4><span class="header-section-number">3.1.1.1</span> Métodos dos quadrados ordinários</h4>
<p>O Método dos quadrados ordinários (MQO) ou método dos mínimos quadrados (MMQ),
busca encontrar o melhor valor para os coeficientes citados anteriormente, de
tal forma que a diferença absoluta entre o valor real e o predito pela função
seja a menor possível entre todos os pontos. A Figura <a href="regressão.html#fig:ols">3.3</a> mostra um
exmplo de regressão linar utilizando o MQO para um conjunto de pontos com força
de correlação de 0,9.</p>
<div class="figure" style="text-align: center"><span id="fig:ols"></span>
<img src="assets/ols.png" alt="Exemplo do método dos quadrados ordinários."  />
<p class="caption">
Figure 3.3: Exemplo do método dos quadrados ordinários.
</p>
</div>
<p>Considerando a Imagem <a href="regressão.html#fig:ols">3.3</a>, uma amostra de 10 pontos como exemplo, que
será chamada de <span class="math inline">\(A\)</span>, ou seja, <span class="math inline">\(A = \{(x_{i}, y_{i}):i=1, ..., 10\}\)</span>. O MQO tem
como objetivo estibular os coeficientes da função, de tal forma que a soma
quadrática dos erros absolutos <span class="math inline">\(E^{2}\)</span> seja a menor possível:</p>
<p><span class="math display" id="eq:error-ols">\[\begin{equation} 
    E^{2} = \sum_{i=1}^{n=10}(y_{i}-(\alpha+\beta x_{i}))^{2}
\tag{3.4}
\end{equation}\]</span></p>
<p>Expandindo a equação fica:</p>
<p><span class="math display" id="eq:expanded-error-ols">\[\begin{equation} 
    E = ((y_{1}-(\alpha+\beta x_{1}))^{2}+(y_{2}-(\alpha+\beta x_{2}))^{2}+ ... + (y_{10}-(\alpha+\beta x_{10}))^{2})^{2}
\tag{3.5}
\end{equation}\]</span></p>
<p>Após isso, é teremos uma função com duas variáveis, e para encontrar seus
valores e igualar a zero, a fim de se obter os pontos críticos, é necessário
calcular as derivadas parciais em relação a <span class="math inline">\(\alpha\)</span> (Equação
<a href="regressão.html#eq:partial-alpha">(3.6)</a> e <span class="math inline">\(\beta\)</span> (Equação <a href="regressão.html#eq:partial-beta">(3.7)</a>.</p>
<!-- = 2(y_{1}-\alpha+\beta x_{1})\times1+2(y_{2}-\alpha+\beta x_{2})\times1+ ... + 2(y_{10}-\alpha+\beta x_{10})\times1 = 0 -->
<p><span class="math display" id="eq:partial-alpha">\[\begin{equation} 
    \frac{\partial E^{2}}{\partial \alpha} = (y_{1}-(\alpha+\beta x_{1}))^{2}+(y_{2}-(\alpha+\beta x_{2}))^{2}+ ... + (y_{10}-(\alpha+\beta x_{10}))^{2} = 0
\tag{3.6}
\end{equation}\]</span></p>
<p><span class="math display" id="eq:partial-beta">\[\begin{equation} 
    \frac{\partial E^{2}}{\partial \beta} = (y_{1}-(\alpha+\beta x_{1}))^{2}+(y_{2}-(\alpha+\beta x_{2}))^{2}+ ... + (y_{10}-(\alpha+\beta x_{10}))^{2} = 0
\tag{3.7}
\end{equation}\]</span></p>
<p>Após calcular as derivadas parcias, teremos duas equações, das quais podemos
encontrar os valores das duas variáveis utilizando um sistema de equações
lineares. Após encontrar as variáveis e realizar as devidas substituições,
teremos a equação da reta, ou seja, a regressão linear.</p>
</div>
<div id="gradiente-descendente" class="section level4" number="3.1.1.2">
<h4><span class="header-section-number">3.1.1.2</span> Gradiente descendente</h4>
<p>O método do gradiente descendente (GD) é uma das técnicas mais utilizadas para
otimização de modelos de ML. O GD é um método interativo que busca encontrar os
coeficiente <span class="math inline">\(\alpha\)</span> e <span class="math inline">\(\beta\)</span> através da minimuzação de uma função de custo,
normalmente o erro quadrático médio (MSE - sigla do inglês,
<em>mean squared error</em>). O MSE pode ser definido pela Equação <a href="regressão.html#eq:mse">(3.8)</a>, onde
<span class="math inline">\(e_{i}\)</span> é a diferença entre o valor real de <span class="math inline">\(y_{i}\)</span> e o valor previsto pela
equação.</p>
<p><span class="math display" id="eq:mse">\[\begin{equation} 
    MSE = \frac{1}{n} \sum^{n}_{i=1}e_{i}^{2}
\tag{3.8}
\end{equation}\]</span></p>
<p>O GD deve ajustar os coeficientes até que o MSE seja o menor possível e cada
intereação. A atualização dos coeficiente é feita com base em uma taxa de
aprendizado, normalmente definida em 0,0001. Uma taxa de aprendizado muito
grande o GD pode cair em um mínimo local, já um valor muito baixo, o modelo pode
demorar muito mais tempo para chegar em um mínimo local, necessitando de muito
mais tempo e processamento, conforme ilustrado na Figura
<a href="regressão.html#fig:learning-rate">3.4</a>.</p>
<div class="figure" style="text-align: center"><span id="fig:learning-rate"></span>
<img src="assets/learning-rate-gd.png" alt="Problemas na taxa de aprendizado do gradiente descendente."  />
<p class="caption">
Figure 3.4: Problemas na taxa de aprendizado do gradiente descendente.
</p>
</div>

</div>
</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="classificação.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="agrupamento.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["intro-ao-machine-learning.pdf"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
